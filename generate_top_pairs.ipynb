{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3bcce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lifelines.statistics import logrank_test\n",
    "from lifelines import KaplanMeierFitter, CoxPHFitter\n",
    "from lifelines import LogLogisticAFTFitter, WeibullAFTFitter, LogNormalAFTFitter\n",
    "\n",
    "from scipy.stats import hmean\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "import pycountry\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "\n",
    "atlas_path = \"./Vivli Data Challenge 2025 - Nachtrab/ATLAS_Antibiotics/2025_03_11 atlas_antibiotics.xlsx\"\n",
    "atlas_df = pd.read_excel(atlas_path)\n",
    "\n",
    "cabbage_path = \"./CABBAGEdata/processed_database/step1_merge_all_v18.csv/step1_merge_all_v18.csv\"\n",
    "cabbage_df = pd.read_csv(cabbage_path)\n",
    "\n",
    "# Only keep the liquid solution typing methods\n",
    "cabbage_df.drop(cabbage_df[cabbage_df[\"measurement_unit\"] != \"mg/l\"].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99e1646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vivli has a single isolate (row) tested on multiple antibio\n",
    "# Cabbage has a single test on a row, with possibly multiple rows per specimen/id\n",
    "\n",
    "atlas_data = atlas_df.copy()\n",
    "cabbage_data = cabbage_df.copy()\n",
    "\n",
    "# Process data to be ingestible for comparison\n",
    "cabbage_data[\"combined_value\"] = cabbage_data[\"measurement_sign\"].fillna(\"\") + cabbage_data[\"measurement_value\"].astype(str).fillna(\"\")\n",
    "\n",
    "cabbage_antibiotics = cabbage_data[\"Antibiotic_name\"].dropna().unique()\n",
    "\n",
    "for abx in cabbage_antibiotics:\n",
    "    cabbage_data[abx] = np.nan\n",
    "\n",
    "for abx in cabbage_antibiotics:\n",
    "    mask = cabbage_data[\"Antibiotic_name\"] == abx\n",
    "    cabbage_data.loc[mask, abx] = cabbage_data.loc[mask, \"combined_value\"]\n",
    "\n",
    "\n",
    "# Now we handle making the values uniform with the vivli data\n",
    "for antibiotic in cabbage_antibiotics:\n",
    "    new_column_name = antibiotic.replace(\"/\", \" \")\n",
    "    if new_column_name == \"Trimethoprim sulfamethoxazole\":\n",
    "        new_column_name = \"Trimethoprim sulfa\"\n",
    "\n",
    "    cabbage_data[new_column_name] = np.where(cabbage_data[\"Antibiotic_name\"] == antibiotic, \n",
    "                                            (cabbage_data[\"measurement_sign\"].fillna('') + cabbage_data[\"measurement_value\"].astype(str)),\n",
    "                                            np.nan)\n",
    "\n",
    "\n",
    "# Create a new Species column for cabbage combining genus and species\n",
    "cabbage_data[\"combined_species\"] = cabbage_data[\"genus\"].astype(str) + \" \" + cabbage_data[\"species\"]\n",
    "\n",
    "# Unify sex\n",
    "cabbage_data['host_sex'] = cabbage_data['host_sex'].replace('male', 1.0)\n",
    "cabbage_data['host_sex'] = cabbage_data['host_sex'].replace('female', 0.0)\n",
    "\n",
    "# Encode phenotype. Cabbage has categories: ['susceptible' 'resistant' 'non-susceptible', 'susceptible dose dependent', 'decreased susceptibility']\n",
    "# Ignore for the moment. Non-susceptible = resistant. Breakpoints change by country, over time, etc\n",
    "encoder = OrdinalEncoder(categories=[['susceptible', 'intermediate', 'resistant', 'decreased susceptibility', 'susceptible dose dependent', 'non-susceptible']])\n",
    "mask = cabbage_data['phenotype'].notna()\n",
    "cabbage_data.loc[mask, 'phenotype_encoded'] = encoder.fit_transform(cabbage_data.loc[mask, ['phenotype']])\n",
    "cabbage_data['phenotype_encoded'] = cabbage_data['phenotype_encoded'].astype('float')\n",
    "\n",
    "# Bin ages. Atlas has defined age groups\n",
    "bins = [0, 2, 12, 18, 64, 84, np.inf]\n",
    "labels = [\"0 to 2 Years\", \"3 to 12 Years\", \"13 to 18 Years\", \n",
    "          \"19 to 64 Years\", \"65 to 84 Years\", \"85 and Over\"]\n",
    "cabbage_data['Age Group'] = pd.cut(cabbage_data['host_age'], bins=bins, labels=labels, right=True)\n",
    "\n",
    "# Encode. TODO: different than vivli - change vivli?\n",
    "age_ordinal = OrdinalEncoder(categories=[labels], \n",
    "                            handle_unknown=\"use_encoded_value\",\n",
    "                            unknown_value=-1,\n",
    "                            dtype=float)\n",
    "cabbage_data['Age Group Encoded'] = age_ordinal.fit_transform(cabbage_data[['Age Group']])\n",
    "cabbage_data['Age Group Encoded'].replace(-1, np.nan, inplace=True)\n",
    "\n",
    "# Convert Year to numerical.\n",
    "cabbage_data['collection_date'].astype('float32')\n",
    "\n",
    "\n",
    "\n",
    "# Encode atlas vivli data into a numerical format\n",
    "\n",
    "# Handle _I columns, [nan 'Susceptible' 'Intermediate' 'Resistant'] into nan, 0, 1, 2\n",
    "columns_of_interest = [col for col in atlas_data.columns if col.endswith('_I')]\n",
    "atlas_antibiotics = [col[:-2] for col in atlas_data.columns]\n",
    "atlas_data[columns_of_interest] = atlas_data[columns_of_interest].astype(\"string\")\n",
    "\n",
    "encoder = OrdinalEncoder(categories=[['Susceptible', 'Intermediate', 'Resistant']] * len(columns_of_interest), \n",
    "                         handle_unknown=\"use_encoded_value\", unknown_value=np.nan, \n",
    "                         dtype=float)\n",
    "atlas_data[columns_of_interest] = encoder.fit_transform(atlas_data[columns_of_interest])\n",
    "\n",
    "\n",
    "# Handle age and gender [using nans]\n",
    "atlas_data['Age Group'] = atlas_data['Age Group'].replace('Unknown', np.nan)\n",
    "age_ordinal = OrdinalEncoder(categories=[[\"0 to 2 Years\", \"3 to 12 Years\", \"13 to 18 Years\", \"19 to 64 Years\", \"65 to 84 Years\", \"85 and Over\"]],\n",
    "                            handle_unknown=\"use_encoded_value\", unknown_value=np.nan, \n",
    "                            dtype=float)\n",
    "\n",
    "atlas_data[\"Age Group\"] = age_ordinal.fit_transform(atlas_data[[\"Age Group\"]])\n",
    "\n",
    "\n",
    "# Male 0.0, Female 1.0\n",
    "atlas_data['Gender'] = atlas_data['Gender'].replace('Unknown', np.nan)\n",
    "gender_ordinal = OrdinalEncoder(categories=[[\"Male\", \"Female\"]],\n",
    "                                handle_unknown=\"use_encoded_value\", unknown_value=np.nan, \n",
    "                                dtype=float)\n",
    "atlas_data[\"Gender\"] = gender_ordinal.fit_transform(atlas_data[[\"Gender\"]])\n",
    "\n",
    "# Substitue the unknown ranks for nan\n",
    "atlas_data['Speciality'] = atlas_data['Speciality'].replace(\"None Given\",np.nan)\n",
    "atlas_data['Speciality'] = atlas_data['Speciality'].replace(\"Other\", np.nan)\n",
    "\n",
    "atlas_data['In / Out Patient'] = atlas_data['In / Out Patient'].replace('None Given', np.nan)\n",
    "atlas_data['In / Out Patient'] = atlas_data['In / Out Patient'].replace('Other', np.nan)\n",
    "\n",
    "# Convert Year to numerical. Corresponds to Cabbage \"collection_date\"\n",
    "atlas_data['Year'].astype('float32')\n",
    "\n",
    "# Convert country to Alpha 3\n",
    "atlas_data[\"country_alpha3\"] = atlas_data[\"Country\"].apply(\n",
    "    lambda x: pycountry.countries.lookup(x).alpha_3 if isinstance(x, str) and pycountry.countries.get(name=x) else None\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get common bacteria and antibiotics\n",
    "overlapping_bacteria = [s.lower() for s in list(set(cabbage_data[\"combined_species\"].unique()) & set(atlas_data[\"Species\"].unique()))]\n",
    "\n",
    "print(f\"overlapping_bacteria length: {len(overlapping_bacteria)}, cabbage species: {len(cabbage_data[\"combined_species\"].unique())}, atlas species: {len(atlas_data[\"Species\"].unique())}\")\n",
    "\n",
    "\n",
    "overlapping_antibio = [s.lower() for s in list(set(cabbage_antibiotics) & set(atlas_antibiotics))]\n",
    "print(f\"overlapping_antibio length: {len(overlapping_antibio)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bc271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weibull estimation\n",
    "# There are 29 species x 36 antibio = 1044 pairs to test\n",
    "\n",
    "# Parse value for Left truncated (late entry) data\n",
    "# https://lifelines.readthedocs.io/en/latest/Survival%20analysis%20with%20lifelines.html#left-truncated-late-entry-data\n",
    "def parse_value(val):\n",
    "    \"\"\"\n",
    "    Parse str '<=2', '>8', '2/32', '=0.5', '16' into (lower, upper) for censoring.\n",
    "    Returns: lower bound, upper bound, observed\n",
    "    \"\"\"\n",
    "    if pd.isna(val):\n",
    "        return (np.nan, np.nan, np.nan)\n",
    "    \n",
    "    val = str(val).strip()\n",
    "    \n",
    "    # Intevals happen when there is ambiguity\n",
    "    if val.startswith(\">,<\"):\n",
    "        val = val[3:].split(\",\")\n",
    "        return (float(val[0]), float(val[1]), True)\n",
    "    \n",
    "    # Right censoring\n",
    "    if val.startswith(\">=\"):\n",
    "        return (float(val[2:]), np.inf, True)\n",
    "    \n",
    "    elif val.startswith(\">\"):\n",
    "        return (float(val[1:]), np.inf, False)\n",
    "    \n",
    "    # <= and < are in practice observed the same way. So both false.\n",
    "    elif val.startswith(\"<=\"):\n",
    "        return (0.0, float(val[2:]), False)\n",
    "    \n",
    "    elif val.startswith(\"<\"):\n",
    "        return (0.0, float(val[1:]), False)\n",
    "    \n",
    "    elif val.startswith(\"=\"):\n",
    "        v = float(val[1:])\n",
    "        return (v, v, True) # Upper value inf? Or v?\n",
    "    \n",
    "    # Just straight up numbers\n",
    "    else:\n",
    "        try:\n",
    "            v = float(val)\n",
    "            return (v, v, True)\n",
    "        except ValueError:\n",
    "            return (np.nan, np.nan, np.nan)\n",
    "\n",
    "\n",
    "\n",
    "def generate_analysis(anal_cabbage_df, anal_atlas_df, species, antibiotic, year, location, gender):\n",
    "\n",
    "    internal_subset = anal_cabbage_df[anal_cabbage_df[\"combined_species\"].str.lower() == species.lower()]\n",
    "    external_subset = anal_atlas_df[anal_atlas_df[\"Species\"].str.lower() == species.lower()]\n",
    "\n",
    "    # Extra filters /!\\ excludes NaNs!!!\n",
    "    if year:\n",
    "        internal_subset = internal_subset[internal_subset[\"collection_date\"].str.lower() == year.lower()]\n",
    "        external_subset = external_subset[external_subset[\"Year\"].str.lower() == year.lower()]\n",
    "    \n",
    "    if location:\n",
    "        internal_subset = internal_subset[internal_subset[\"isolation_country\"].str.lower() == location.lower()]\n",
    "        external_subset = external_subset[external_subset[\"country_alpha3\"].str.lower() == location.lower()]\n",
    "\n",
    "    if gender:\n",
    "        internal_subset = internal_subset[internal_subset[\"host_sex\"].str.lower() == gender.lower()]\n",
    "        external_subset = external_subset[external_subset[\"Gender\"].str.lower() == gender.lower()]\n",
    "    \n",
    "\n",
    "\n",
    "    # Check if too little data\n",
    "    if len(internal_subset) < len(external_subset)/100 or len(external_subset) < len(internal_subset)/100:\n",
    "        print(f\"Imbalanced data, cab {len(internal_subset)}, atlas {len(external_subset)}\")\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    \n",
    "    cabbage_col = next(col for col in anal_cabbage_df.columns if col.lower() == antibiotic.lower())\n",
    "    atlas_col = next(col for col in anal_atlas_df.columns if col.lower() == antibiotic.lower())\n",
    "    \n",
    "    # Parse values from the given antibiotic column\n",
    "    parsed_int = internal_subset[cabbage_col].dropna().apply(parse_value)\n",
    "    parsed_ext = external_subset[atlas_col].dropna().apply(parse_value)\n",
    "\n",
    "    if len(parsed_int) < 10 or len(parsed_ext) < 10:\n",
    "        print(f\"Too little parsed data, cab {len(parsed_int)}, atlas {len(parsed_ext)}\")\n",
    "        return None\n",
    "    \n",
    "    print(len(parsed_int))\n",
    "    print(len(parsed_ext))\n",
    "    \n",
    "    T_int_lower = np.array([p[0] for p in parsed_int])\n",
    "    T_int_upper = np.array([p[1] for p in parsed_int])\n",
    "    T_int_obsrv = np.array([p[2] for p in parsed_int])\n",
    "    \n",
    "    T_ext_lower = np.array([p[0] for p in parsed_ext])\n",
    "    T_ext_upper = np.array([p[1] for p in parsed_ext])\n",
    "    T_ext_obsrv = np.array([p[2] for p in parsed_ext])\n",
    "\n",
    "    df_int = pd.DataFrame({\n",
    "        \"T_lower\": T_int_lower,\n",
    "        \"T_upper\": T_int_upper\n",
    "    })\n",
    "\n",
    "    df_ext = pd.DataFrame({\n",
    "        \"T_lower\": T_ext_lower,\n",
    "        \"T_upper\": T_ext_upper\n",
    "    })\n",
    "\n",
    "\n",
    "    aft_int = WeibullAFTFitter()\n",
    "    aft_int.fit_interval_censoring(df_int, lower_bound_col=\"T_lower\", upper_bound_col=\"T_upper\")\n",
    "\n",
    "    aft_ext = WeibullAFTFitter()\n",
    "    aft_ext.fit_interval_censoring(df_ext, lower_bound_col=\"T_lower\", upper_bound_col=\"T_upper\")\n",
    "\n",
    "    return {\n",
    "        \"species\": species,\n",
    "        \"antibiotic\": antibiotic,\n",
    "        \"weibull_cabbage\": aft_int,\n",
    "        \"weibull_atlas\": aft_ext\n",
    "    }\n",
    "\n",
    "\n",
    "results = []\n",
    "i = 0\n",
    "j = 0\n",
    "for species in overlapping_bacteria:\n",
    "    print(f\"Analysing all antibiotics for {species}\")\n",
    "    if i > 3:\n",
    "        break\n",
    "\n",
    "    for antibiotic in overlapping_antibio:\n",
    "        if j > 10:\n",
    "            break\n",
    "        row = generate_analysis(cabbage_data, atlas_data, species, antibiotic, None, None, None)\n",
    "        if row:\n",
    "            results.append(row)\n",
    "            j = j+1\n",
    "    j = 0\n",
    "    i = i+1\n",
    "        \n",
    "\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de141b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 29 species x 36 antibio = 1044 pairs to test\n",
    "\n",
    "# Parse value for Left truncated (late entry) data\n",
    "# https://lifelines.readthedocs.io/en/latest/Survival%20analysis%20with%20lifelines.html#left-truncated-late-entry-data\n",
    "def parse_value(val):\n",
    "    \"\"\"\n",
    "    Parse str '<=2', '>8', '2/32', '=0.5', '16' into (lower, upper) for censoring.\n",
    "    Returns: lower bound, upper bound, observed\n",
    "    \"\"\"\n",
    "    if pd.isna(val):\n",
    "        return (np.nan, np.nan, np.nan)\n",
    "    \n",
    "    val = str(val).strip()\n",
    "    \n",
    "    # Intevals happen when there is ambiguity\n",
    "    if val.startswith(\">,<\"):\n",
    "        val = val[3:].split(\",\")\n",
    "        return (float(val[0]), float(val[1]), True)\n",
    "    \n",
    "    # Right censoring\n",
    "    if val.startswith(\">=\"):\n",
    "        return (float(val[2:]), np.inf, True)\n",
    "    \n",
    "    elif val.startswith(\">\"):\n",
    "        return (float(val[1:]), np.inf, False)\n",
    "    \n",
    "    # <= and < are in practice observed the same way. So both false.\n",
    "    elif val.startswith(\"<=\"):\n",
    "        return (0.0, float(val[2:]), False)\n",
    "    \n",
    "    elif val.startswith(\"<\"):\n",
    "        return (0.0, float(val[1:]), False)\n",
    "    \n",
    "    elif val.startswith(\"=\"):\n",
    "        v = float(val[1:])\n",
    "        return (v, v, True) # Upper value inf? Or v?\n",
    "    \n",
    "    # Just straight up numbers\n",
    "    else:\n",
    "        try:\n",
    "            v = float(val)\n",
    "            return (v, v, True)\n",
    "        except ValueError:\n",
    "            return (np.nan, np.nan, np.nan)\n",
    "\n",
    "\n",
    "\n",
    "def generate_analysis(anal_cabbage_df, anal_atlas_df, species, antibiotic, year, location, gender):\n",
    "\n",
    "    internal_subset = anal_cabbage_df[anal_cabbage_df[\"combined_species\"].str.lower() == species.lower()]\n",
    "    external_subset = anal_atlas_df[anal_atlas_df[\"Species\"].str.lower() == species.lower()]\n",
    "\n",
    "    # Extra filters /!\\ excludes NaNs!!!\n",
    "    if year:\n",
    "        internal_subset = internal_subset[internal_subset[\"collection_date\"].str.lower() == year.lower()]\n",
    "        external_subset = external_subset[external_subset[\"Year\"].str.lower() == year.lower()]\n",
    "    \n",
    "    if location:\n",
    "        internal_subset = internal_subset[internal_subset[\"isolation_country\"].str.lower() == location.lower()]\n",
    "        external_subset = external_subset[external_subset[\"country_alpha3\"].str.lower() == location.lower()]\n",
    "\n",
    "    if gender:\n",
    "        internal_subset = internal_subset[internal_subset[\"host_sex\"].str.lower() == gender.lower()]\n",
    "        external_subset = external_subset[external_subset[\"Gender\"].str.lower() == gender.lower()]\n",
    "    \n",
    "\n",
    "\n",
    "    # Check if too little data\n",
    "    if len(internal_subset) < len(external_subset)/100 or len(external_subset) < len(internal_subset)/100:\n",
    "        print(f\"Imbalanced data, cab {len(internal_subset)}, atlas {len(external_subset)}\")\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    \n",
    "    # print(f\"Enough data: cab {len(internal_subset)}, atlas {len(external_subset)}\")\n",
    "\n",
    "    \n",
    "    cabbage_col = next(col for col in anal_cabbage_df.columns if col.lower() == antibiotic.lower())\n",
    "    atlas_col = next(col for col in anal_atlas_df.columns if col.lower() == antibiotic.lower())\n",
    "    \n",
    "    # Parse values from the given antibiotic column\n",
    "    parsed_int = internal_subset[cabbage_col].dropna().apply(parse_value)\n",
    "    parsed_ext = external_subset[atlas_col].dropna().apply(parse_value)\n",
    "\n",
    "    if len(parsed_int) < 10 or len(parsed_ext) < 10:\n",
    "        print(f\"Too little parsed data, cab {len(parsed_int)}, atlas {len(parsed_ext)}\")\n",
    "        return None\n",
    "    \n",
    "    print(len(parsed_int))\n",
    "    print(len(parsed_ext))\n",
    "    \n",
    "    T_int_lower = np.array([p[0] for p in parsed_int])\n",
    "    T_int_upper = np.array([p[1] for p in parsed_int])\n",
    "    T_int_obsrv = np.array([p[2] for p in parsed_int])\n",
    "    \n",
    "    T_ext_lower = np.array([p[0] for p in parsed_ext])\n",
    "    T_ext_upper = np.array([p[1] for p in parsed_ext])\n",
    "    T_ext_obsrv = np.array([p[2] for p in parsed_ext])\n",
    "\n",
    "    df_int = pd.DataFrame({\n",
    "        \"T_lower\": T_int_lower,\n",
    "        \"T_upper\": T_int_upper\n",
    "    })\n",
    "\n",
    "    df_ext = pd.DataFrame({\n",
    "        \"T_lower\": T_ext_lower,\n",
    "        \"T_upper\": T_ext_upper\n",
    "    })\n",
    "\n",
    "\n",
    "    # aft_int = WeibullAFTFitter()\n",
    "    # aft_int.fit_interval_censoring(df_int, lower_bound_col=\"T_lower\", upper_bound_col=\"T_upper\")\n",
    "\n",
    "    # aft_ext = WeibullAFTFitter()\n",
    "    # aft_ext.fit_interval_censoring(df_ext, lower_bound_col=\"T_lower\", upper_bound_col=\"T_upper\")\n",
    "\n",
    "\n",
    "    # mask_int = ~np.isnan(T_int) & ~np.isnan(T_int_upper)\n",
    "    # mask_ext = ~np.isnan(T_ext) & ~np.isnan(T_ext_upper)\n",
    "\n",
    "\n",
    "    # kmf_cabbage = KaplanMeierFitter()\n",
    "    # kmf_atlas = KaplanMeierFitter()\n",
    "\n",
    "    # if mask_int.sum() > 0:\n",
    "    #     kmf_cabbage.fit_interval_censoring(T_int[mask_int], T_int_upper[mask_int], label=\"Cabbage\")\n",
    "\n",
    "    # if mask_ext.sum() > 0:\n",
    "    #     kmf_atlas.fit_interval_censoring(T_ext[mask_ext], T_ext_upper[mask_ext], label=\"Atlas\")\n",
    "\n",
    "\n",
    "    # # CABBAGE exact or right-censored only\n",
    "    # durations_A = []\n",
    "    # event_A = []\n",
    "    # for t, t_up in zip(T_int[mask_int], T_int_upper[mask_int]):\n",
    "    #     if np.isinf(t_up):  # right-censored\n",
    "    #         durations_A.append(t)\n",
    "    #         event_A.append(0)\n",
    "    #     elif t == t_up:  # exact\n",
    "    #         durations_A.append(t)\n",
    "    #         event_A.append(1)\n",
    "    #     # else:\n",
    "    #     #     print(f\"t: {t}, t_up: {t_up}\")\n",
    "\n",
    "\n",
    "    # # ATLAS\n",
    "    # durations_B = []\n",
    "    # event_B = []\n",
    "    # for t, t_up in zip(T_ext[mask_ext], T_ext_upper[mask_ext]):\n",
    "    #     if np.isinf(t_up):  # right-censored\n",
    "    #         durations_B.append(t)\n",
    "    #         event_B.append(0)\n",
    "    #     elif t == t_up:  # exact\n",
    "    #         durations_B.append(t)\n",
    "    #         event_B.append(1)\n",
    "    #     # else:\n",
    "    #     #     print(f\"t: {t}, t_up: {t_up}\")\n",
    "\n",
    "\n",
    "    #  # Again check if too short/small\n",
    "    # if len(durations_A) < len(durations_B)/100 or len(durations_B) < len(durations_A)/100:\n",
    "    #     print(f\"cox too sort/small, durA {len(durations_A)}, durB {len(durations_B)}\")\n",
    "    #     return None\n",
    "\n",
    "\n",
    "    # # Create combined dataframe\n",
    "    # dfA = pd.DataFrame({'T': durations_A, 'E': event_A, 'group': 1})\n",
    "    # dfB = pd.DataFrame({'T': durations_B, 'E': event_B, 'group': 0})\n",
    "    # df = pd.concat([dfA, dfB])\n",
    "\n",
    "    # # Fit Cox model\n",
    "    # try:\n",
    "    #     cph = CoxPHFitter().fit(df, duration_col='T', event_col='E')\n",
    "    #     summary = cph.summary\n",
    "    #     p = summary.loc[\"group\", \"p\"]\n",
    "    #     if p>0.001:\n",
    "    #         print(\"higher than 0.001\")\n",
    "    # except Exception as e:\n",
    "    #     print(\"Couldn't fit cox\")\n",
    "    #     return None\n",
    "    \n",
    "    return {\n",
    "        \"species\": species,\n",
    "        \"antibiotic\": antibiotic,\n",
    "        # \"weibull_cabbage\": aft_int,\n",
    "        # \"weibull_atlas\": aft_ext,\n",
    "        # \"p_value\": p,\n",
    "        \"n_internal\": len(parsed_int),\n",
    "        \"n_external\": len(parsed_ext),\n",
    "        # \"dur_a\":durations_A,\n",
    "        # \"dur_b\":durations_B,\n",
    "        # \"len_internal\": len(internal_subset),\n",
    "        # \"len_external\": len(external_subset),\n",
    "        # \"kmf_cabbage\": kmf_cabbage,\n",
    "        # \"kmf_atlas\": kmf_atlas\n",
    "    }\n",
    "\n",
    "\n",
    "results = []\n",
    "i = 0\n",
    "j = 0\n",
    "for species in overlapping_bacteria:\n",
    "    print(f\"Analysing all antibiotics for {species}\")\n",
    "    if i > 100:\n",
    "        break\n",
    "\n",
    "    for antibiotic in overlapping_antibio:\n",
    "        if j > 100:\n",
    "            break\n",
    "        row = generate_analysis(cabbage_data, atlas_data, species, antibiotic, None, None, None)\n",
    "        if row:\n",
    "            results.append(row)\n",
    "            j = j+1\n",
    "    j = 0\n",
    "    i = i+1\n",
    "        \n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df[\"balance_score\"] = results_df.apply(\n",
    "    lambda row: hmean([row[\"n_internal\"], row[\"n_external\"]]) if row[\"n_internal\"] > 0 and row[\"n_external\"] > 0 else 0,\n",
    "    axis=1\n",
    ")\n",
    "sorted_df = results_df.sort_values(by=\"balance_score\", ascending=False)\n",
    "sorted_df.to_csv('./generated_data/sorted_species_antibio_pairs.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
